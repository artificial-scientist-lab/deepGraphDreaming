#!/bin/bash -l
#SBATCH --array=2
#SBATCH --gpus-per-node=1         # specify number of GPUs
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --account=def-ekarimi
# Standard output and error:
#SBATCH -o ./jobfiles/out.%j
#SBATCH -e ./jobfiles/err.%j
#SBATCH -D ./
#SBATCH -J trainFurLossType12

#srun ./script $SLURM_ARRAY_TASK_ID 

# memory
#SBATCH --mem=180GB
#SBATCH --time=165:00:00

module load python/3.9
module load scipy-stack
source venv/bin/activate

srun python train.py --ii $SLURM_ARRAY_TASK_ID